{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kirbyju/TCIA-Citation-Parser/blob/master/Accessing_and_visualizing_DICOM_datasets_hosted_on_TCIA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Summary\n",
        "\n",
        "Access to large, high quality data is essential for researchers to understand disease and precision medicine pathways, especially in cancer. However HIPAA constraints make sharing medical images outside an individual institution a complex process. [The Cancer Imaging Archive (TCIA)](https://www.cancerimagingarchive.net/) is a public service funded by the National Cancer Institute which addresses this challenge by providing hosting and de-identification services to take major burdens of data sharing off researchers. \n",
        "\n",
        "TCIA has published over 175 unique data collections containing more than 60 million images. Recognizing that images alone are not enough to conduct meaningful research, most collections are linked to rich supporting data including patient outcomes, treatment information, genomic / proteomic analyses, and expert image analyses (segmentations, annotations, and radiomic features). This notebook is focused on basic use cases for identifying TCIA datasets of interest and downloading them using command line tools and/or Python."
      ],
      "metadata": {
        "id": "KmXfYFZtja2F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1 Learn about available Collections on the TCIA website\n",
        "\n",
        "[Browsing Collections](https://www.cancerimagingarchive.net/collections) and [Analysis Results](https://www.cancerimagingarchive.net/tcia-analysis-results/) datasets on TCIA are the easiest ways to become familiar with what is available.  These pages will help you quickly identify datasets of interest, find valuable supporting data that are not available via our APIs (e.g. clinical spreadsheets, non-DICOM segmentation data), and answer most common questions you might have about the datasets.  "
      ],
      "metadata": {
        "id": "AruUGe3lmjkh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2 Downloading with NBIA Data Retriever\n",
        "\n",
        "TCIA utilizes software called NBIA to manage its DICOM data.  One way to download TCIA data is to install the [linux command-line version of the NBIA Data Retriever](https://wiki.cancerimagingarchive.net/x/2QKPBQ) using the following steps.  This tool provides a number of useful features such as multi-threaded downloads, auto-retry if there are any problems, saving data in an organized hierarchy on your hard drive (Collection > Patient > Study > Series > Images) and providing a CSV file containing key DICOM metadata about the images you've downloaded."
      ],
      "metadata": {
        "id": "aUw6d8fbgb8Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.1 Install the NBIA Data Retriever CLI package"
      ],
      "metadata": {
        "id": "RtLE_18NoaJ8"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B714bOkDk8kd"
      },
      "source": [
        "# install NBIA Data Retriever CLI software for downloading images later in this notebook\n",
        "\n",
        "!mkdir /usr/share/desktop-directories/\n",
        "!wget -P /content/NBIA-Data-Retriever https://cbiit-download.nci.nih.gov/nbia/releases/ForTCIA/NBIADataRetriever_4.4/nbia-data-retriever-4.4.deb\n",
        "!dpkg -i /content/NBIA-Data-Retriever/nbia-data-retriever-4.4.deb\n",
        "\n",
        "# NOTE: If you're working on a Linux OS that uses RPM packages you can try changing the wget line above to point to\n",
        "#       https://cbiit-download.nci.nih.gov/nbia/releases/ForTCIA/NBIADataRetriever_4.4/NBIADataRetriever-4.4-1.x86_64.rpm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.2 Download a manifest file\n",
        "The Data Retriever software works by ingesting a \"manifest\" file that contains the DICOM Series Instance UIDs of the scans you'd like to download. Let's assume that after [Browsing the Collections](https://www.cancerimagingarchive.net/collections) you decided you were interested in the [RIDER Breast MRI](https://doi.org/10.7937/K9/TCIA.2015.H1SXNUXL) Collection.  If you're working from your local machine you can simply click the blue \"Download\" button on the [RIDER Breast MRI](https://doi.org/10.7937/K9/TCIA.2015.H1SXNUXL) page to save the manifest file to your computer.  If you're working on Google Colab or some other remote server the easiest thing to do is use wget to save it to your VM as shown below.\n",
        "\n"
      ],
      "metadata": {
        "id": "2uMbL1nwIJ5f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# use wget to download the manifest\n",
        "\n",
        "!wget -O /content/RIDER-Breast-MRI.tcia https://wiki.cancerimagingarchive.net/download/attachments/22512757/doiJNLP-Fo0H1NtD.tcia?version=1&modificationDate=1534787017928&api=v2\n"
      ],
      "metadata": {
        "id": "pAtUWEcSHiO5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# OPTIONAL: If you're just looking for a quick demo, you can run this command \n",
        "# to edit the manifest file to download only the first 3 scans\n",
        "\n",
        "!head -n 9 /content/RIDER-Breast-MRI.tcia > /content/RIDER-Breast-MRI-Sample.tcia"
      ],
      "metadata": {
        "id": "ikegl1vLYDkZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.3 Open the manifest file with NBIA Data Retriever\n",
        "Next let's open the sample manifest file with Data Retriever to download the actual DICOM data.\n",
        "\n",
        "***Note: After running the following command you have to click in the output cell, type \"y\" and press Enter to agree with the TCIA Data Usage Policy to start the download.***"
      ],
      "metadata": {
        "id": "IlPLgxkBZPMS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# download the data using NBIA Data Retriever\n",
        "\n",
        "!/opt/nbia-data-retriever/nbia-data-retriever --cli '/content/RIDER-Breast-MRI-Sample.tcia' -d /content/ \n"
      ],
      "metadata": {
        "id": "a4lklpk4Xwpc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.4 Review the downloaded data\n",
        "You should now find that the data have been saved to your machine in a well organized hierarchy with some useful metadata in the accompanying CSV file and a license file detailing how it can be used.  Take a second to go check it out before moving on!"
      ],
      "metadata": {
        "id": "zgESwVXSawv_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.5 Downloading \"Limited-Access\" Collections with the Data Retriever\n",
        "In some cases you must specifically request access to [Collections](https://www.cancerimagingarchive.net/collections/) before you can download them.  Information about how to do this can be found on the homepage for the Collection(s) that you're interested in, but will always require that you first [create a TCIA user account](https://wiki.cancerimagingarchive.net/x/xgHDAg.).  Once you've created an account you can use your login/password to create the credential file that NBIA Data Retriever uses to verify your permissions."
      ],
      "metadata": {
        "id": "39ilU9kTkac3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the credential file\n",
        "# NOTE: You must enter your real user name and password before you run this,\n",
        "# or edit the resulting text file with your real credentials after it's created.\n",
        "\n",
        "lines = ['userName=YourUserName', 'passWord=YourPassword']\n",
        "with open('credentials.txt', 'w') as f:\n",
        "    f.write('\\n'.join(lines))"
      ],
      "metadata": {
        "id": "WWRfMGQJmyjR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's say that we're interested in the [RIDER Neuro MRI](http://doi.org/10.7937/K9/TCIA.2015.VOSN3HN1) Collection. As you can see on the Collection page, you must sign and submit a TCIA Restricted License Agreement to help@cancerimagingarchive.net before accessing the data. Once you've done this, click the blue Download button on the RIDER Neuro MRI page to save the manifest file to your computer or grab it by using the wget command shown below."
      ],
      "metadata": {
        "id": "hit1qkiloRaX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# download a manifest with the restricted data\n",
        "!wget -O /content/RIDER_Neuro_MRI.tcia https://wiki.cancerimagingarchive.net/download/attachments/22512753/TCIA_RIDER_NEURO_MRI_06-22-2015.tcia?version=1&modificationDate=1534787443910&api=v2\n"
      ],
      "metadata": {
        "id": "QvYf6HtInRXP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# OPTIONAL: If you're just looking for a quick demo, you can run this command \n",
        "# to edit the manifest file to download only the first 3 scans\n",
        "\n",
        "!head -n 9 /content/RIDER_Neuro_MRI.tcia > /content/RIDER_Neuro_MRI-Sample.tcia"
      ],
      "metadata": {
        "id": "OsISov9hEatv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's open the manifest file with NBIA Data Retriever to download your data.This time we're also invoking the \"-l\" parameter to tell it where you saved your credential file.\n",
        "\n",
        "***Note: After running the following command you have to click in the output cell, type \"y\" and press Enter to agree with the TCIA Data Usage Policy to start the download.***"
      ],
      "metadata": {
        "id": "vCjyQWmwRFDp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# download the data using NBIA Data Retriever\n",
        "# you may need to update the path to your credential file\n",
        "\n",
        "!/opt/nbia-data-retriever/nbia-data-retriever --cli '/content/RIDER_Neuro_MRI-Sample.tcia' -d /content/ -l /content/credentials.txt"
      ],
      "metadata": {
        "id": "pbAUZ3jznRXR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SmeqJoR5k9z0"
      },
      "source": [
        "# 3 Searching and downloading data via the REST APIs \n",
        "NBIA REST APIs are provided to the search and download functions used in the TCIA radiology portal, and allow access to both public and limited access collections.\n",
        "1. The [NBIA Search REST APIs](https://wiki.cancerimagingarchive.net/x/fILTB) allow you to perform basic queries and download data from **public** collections. This API does not require a TCIA account.\n",
        "2. The [NBIA Search with Authentication REST APIs](https://wiki.cancerimagingarchive.net/x/X4ATBg) allow you to perform basic queries and download data from **public and limited-access** collections. This API requires a TCIA account for creation of authentication tokens.\n",
        "3. The [NBIA Advanced REST APIs](https://wiki.cancerimagingarchive.net/x/YoATBg) also allow access to **public and limited-access** collections, but provides query endpoints mostly geared towards developers seeking to integrate searching and downloading TCIA data into web and desktop applications.  This API requires a TCIA account for creation of authentication tokens.\n",
        "\n",
        "Thise notebook will focus on the fully public [NBIA Search REST APIs](https://wiki.cancerimagingarchive.net/x/fILTB).  If you'd like to see examples using the other APIs check out [this notebook](https://github.com/kirbyju/TCIA_Notebooks/blob/main/ACNS0332/ACNS0332.ipynb) which shows many similar examples with the additional steps necessary to create a secure token using your TCIA login credentials.\n",
        "\n",
        "***Note:*** Many of the examples below allow for additional query parameters to refine your search results.  These are covered in the documentation links above."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.1 Explore public data with REST API Queries\n",
        "In this section we'll look at how to query and download public data via the [NBIA Search REST APIs](https://wiki.cancerimagingarchive.net/x/fILTB).  The URL for accessing the Search APIs changes slightly depending on whether or not you would like to access the [National Lung Screening Trial (NLST)](https://doi.org/10.7937/TCIA.HMQ8-J677) collection, which lives on its own server due to its size (26,000+ patients, ~13 TBytes).  Here are the base URLs:\n",
        "\n",
        "* All other Collections - https://services.cancerimagingarchive.net/nbia-api/services/v1/\n",
        "* NLST - https://services.cancerimagingarchive.net/nlst-api/services/v1/\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "nj6P7YCmll4S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# set API base URLs\n",
        "\n",
        "base_url = \"https://services.cancerimagingarchive.net/nbia-api/services/v1/\"\n",
        "nlst_url = \"https://services.cancerimagingarchive.net/nlst-api/services/v1/\"\n",
        "\n",
        "# imports\n",
        "\n",
        "import requests\n",
        "import pandas as pd\n",
        "import json"
      ],
      "metadata": {
        "id": "FlK684ooivTC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3.1.1 List collections and determine modalities and body parts\n",
        "Let's run a query to see what Collections are available.  After obtaining a list we'll use some example queries to learn more about specific Collections."
      ],
      "metadata": {
        "id": "kb-9XC9rEdmc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# get list of available collections as JSON\n",
        "\n",
        "data_url = base_url + \"getCollectionValues\"\n",
        "data = requests.get(data_url).json()\n",
        "print(json.dumps(data, indent=2))"
      ],
      "metadata": {
        "id": "II1o1709zq1d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's choose a Collection from the list above and find out more about what modalities and body parts it contains.  We'll define these as functions so we can use them as part of more complex queries later in the notebook."
      ],
      "metadata": {
        "id": "1amXAIvsgQLg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a function to return modalities for a collection as JSON\n",
        "\n",
        "# Choose a collection of interest\n",
        "collection = \"TCGA-LUAD\"\n",
        "\n",
        "def getModality(collection):\n",
        "    data_url = base_url + \"getModalityValues?Collection=\" + collection\n",
        "    data = requests.get(data_url)\n",
        "    if data.text != \"\":\n",
        "        return data.json()\n",
        "    else:\n",
        "        print(\"Collection not found.\")\n",
        "\n",
        "getModality(collection)"
      ],
      "metadata": {
        "id": "0koEKWjmieYM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a function to return body parts examined for a collection as JSON\n",
        "collection = \"TCGA-LUAD\"\n",
        "\n",
        "def getBodyPart(collection):\n",
        "    data_url = base_url + \"getBodyPartValues?Collection=\" + collection\n",
        "    data = requests.get(data_url)\n",
        "    if data.text != \"\":\n",
        "        return data.json()\n",
        "    else:\n",
        "        print(\"Collection not found.\")\n",
        "\n",
        "getBodyPart(collection)"
      ],
      "metadata": {
        "id": "aQBt2TrC6m0H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3.1.2 Exploring patient, study and scan metadata\n",
        "You can use the /getPatient endpoint to obtain details about species, gender, and ethnicity where available for a given collection. You can also learn whether a [phantom](https://www.nist.gov/physics/what-are-imaging-phantoms) subject or not."
      ],
      "metadata": {
        "id": "1EHAjkALWsGH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Retrieve patient details as JSON and create pandas dataframe w/ optional file export\n",
        "\n",
        "# Choose a collection of interest\n",
        "collection=\"CPTAC-CCRCC\"\n",
        "\n",
        "data_url = base_url + \"getPatient?Collection=\" + collection\n",
        "data = requests.get(data_url)\n",
        "\n",
        "if data.text != \"\":\n",
        "    df = pd.DataFrame(data.json())\n",
        "    display(df)\n",
        "    # optional - save to JSON or CSV file\n",
        "    df.to_csv(collection+'_patient_metadata.csv')\n",
        "    # df.to_json(collection+'_patient_metadata.json')\n",
        "else:\n",
        "    print(\"Collection not found.\")\n"
      ],
      "metadata": {
        "id": "k4Ge-Z-9H_hr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here's an example that does the same thing with the NLST collection, which is living on its own server and uses the slightly modified API URL.  Any of the other queries shown in the notebook should work simply by setting the collection variable to \"NLST\" and updating \"base_url\" to the \"nlst_url\" in the \"data_url\" variable as shown here."
      ],
      "metadata": {
        "id": "kv8RCpe30TR8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Retrieve patient details as JSON and create pandas dataframe w/ optional file export\n",
        "\n",
        "# Choose a collection of interest\n",
        "collection=\"NLST\"\n",
        "\n",
        "# NOTE: we are using the nlst_url variable rather than the general base_url\n",
        "data_url = nlst_url + \"getPatient?Collection=\" + collection\n",
        "data = requests.get(data_url)\n",
        "\n",
        "if data.text != \"\":\n",
        "    df = pd.DataFrame(data.json())\n",
        "    display(df)\n",
        "    # optional - save to JSON or CSV file\n",
        "    df.to_csv(collection+'_patient_metadata.csv')\n",
        "    # df.to_json(collection+'_patient_metadata.json')\n",
        "else:\n",
        "    print(\"Collection not found.\")"
      ],
      "metadata": {
        "id": "gMC3WCQ20cfd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The /getStudy endpoint can be used to obtain study/visit details such as the anonymized study date, subject's age at the time of visit, number of scans acquired each timepoint and more."
      ],
      "metadata": {
        "id": "XbecJEQGfZ5y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# getStudy details for collection and create pandas dataframe w/ optional file export\n",
        "\n",
        "collection=\"CPTAC-CCRCC\"\n",
        "\n",
        "data_url = base_url + \"getPatientStudy?Collection=\" + collection\n",
        "data = requests.get(data_url)\n",
        "\n",
        "if data.text != \"\":\n",
        "    df = pd.DataFrame(data.json())\n",
        "    display(df)\n",
        "    # optional - save to JSON or CSV file\n",
        "    df.to_csv(collection+'_study_metadata.csv')\n",
        "    # df.to_json(collection+'_study_metadata.json')\n",
        "else:\n",
        "    print(\"Collection not found.\")"
      ],
      "metadata": {
        "id": "ivLAjjuK8nPv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can also create reports that give useful metadata about each scan in the dataset (e.g. series description, modality, scanner manufacturer & software version, number of images).  We'll define a function for this one as well so we can use the JSON output in a more complex query later.  You must choose a collection, but modality is optional."
      ],
      "metadata": {
        "id": "bEbkXARGg6W6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a function to return scan/series metadata for a collection as JSON \n",
        "# modality is optional\n",
        "\n",
        "collection = \"LIDC-IDRI\"\n",
        "modality = \"\"\n",
        "\n",
        "def getSeries(collection, modality=\"\"):\n",
        "    if modality != \"\":\n",
        "        data_url = base_url + \"getSeries?Collection=\" + collection + \"&Modality=\" + modality\n",
        "        data = requests.get(data_url)\n",
        "        if data.text != \"\":\n",
        "            return data.json()\n",
        "        else:\n",
        "            print(\"No results: Please check to make sure the Collection \" + collection + \" exists and it contains \" + modality + \" modality.\")\n",
        "    else:\n",
        "        data_url = base_url + \"getSeries?Collection=\" + collection\n",
        "        data = requests.get(data_url)\n",
        "        if data.text != \"\":\n",
        "            return data.json()\n",
        "        else:\n",
        "            print(\"Collection not found.\")\n",
        "\n",
        "getSeries(collection, modality)"
      ],
      "metadata": {
        "id": "M34I2o90kofo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's save the output from that function in a dataframe so it's easier to view, analyze and export to CSV (if desired)."
      ],
      "metadata": {
        "id": "P5GAzyVQBY5m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "collection = \"LIDC-IDRI\"\n",
        "modality = \"\"\n",
        "\n",
        "# call previously created getSeries function for a given Collection\n",
        "data = getSeries(collection, modality)\n",
        "\n",
        "# load it to a dataframe\n",
        "df = pd.DataFrame(data)\n",
        "display(df)\n",
        "\n",
        "# optional - save to JSON or CSV file\n",
        "#df.to_csv(collection+'_scan_metadata.csv')\n",
        "# df.to_json(collection+'_scan_metadata.json')"
      ],
      "metadata": {
        "id": "w3ffXjBCR-vw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3.1.3 Advanced queries\n",
        "Here are some additional examples which can be useful to address common questions about TCIA's datasets.  These are where we will rely on some of the functions we defined earlier in the notebook."
      ],
      "metadata": {
        "id": "zwndv4gJBz1Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Find out how many patients, which modalities and body parts are in a collection\n",
        "\n",
        "# set collection of interest\n",
        "collection = \"QIN-PROSTATE-Repeatability\"\n",
        "\n",
        "# get list of patients in Collection\n",
        "data_url = base_url + \"getPatient?Collection=\" + collection\n",
        "data = requests.get(data_url)\n",
        "\n",
        "if data.text != \"\":\n",
        "    # get modalities for collection\n",
        "    modalities = getModality(collection)\n",
        "    clean_modalities = set(item['Modality'] for item in modalities)\n",
        "    # get body parts for collection\n",
        "    bodyParts = getBodyPart(collection)\n",
        "    clean_bodyParts = set()\n",
        "    # replace null bodyParts with \"Not Specified\"\n",
        "    for item in bodyParts:\n",
        "        if len(item):\n",
        "            clean_bodyParts.add(item['BodyPartExamined'])\n",
        "        else:\n",
        "            clean_bodyParts.add('Not Specified')\n",
        "    # print cleaned up results\n",
        "    print(collection, 'has', len(data.json()), 'patients,',\n",
        "        clean_modalities, 'modalities, and',\n",
        "        clean_bodyParts, 'anatomic entities')\n",
        "else:\n",
        "    print(\"Collection not found.\")"
      ],
      "metadata": {
        "id": "O9v6sVfePaUJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate summary statistics for a given collection \n",
        "collection = \"CPTAC-LSCC\"\n",
        "\n",
        "# Call the getSeries function we created above\n",
        "data = getSeries(collection)\n",
        "\n",
        "# convert the output to dataframe\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Summarize patients\n",
        "print('Summary Statistics\\n')\n",
        "print('Subjects: ', len(df['PatientID'].value_counts()), 'subjects')\n",
        "print('Subjects: ', len(df['StudyInstanceUID'].value_counts()), 'studies')\n",
        "print('Subjects: ', len(df['SeriesInstanceUID'].value_counts()), 'series')\n",
        "print('Images: ', df['ImageCount'].sum(), 'images\\n')\n",
        "\n",
        "# Summarize modalities\n",
        "print(\"Series Counts - Modalities:\")\n",
        "print(df['Modality'].value_counts(dropna=False),'\\n')\n",
        "\n",
        "# Summarize body parts\n",
        "print(\"Series Counts - Body Parts Examined:\")\n",
        "print(df['BodyPartExamined'].value_counts(dropna=False),'\\n')\n",
        "\n",
        "# Summarize manufacturers\n",
        "print(\"Series Counts - Device Manufacturers:\")\n",
        "print(df['Manufacturer'].value_counts(dropna=False))"
      ],
      "metadata": {
        "id": "CzkViZxej3ew"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get patient counts for a given modality across all Collections\n",
        "# this is particularly useful for finding Collections w/ segmentation labels (SEG/RTSTRUCT)\n",
        "\n",
        "modality = \"SEG\"\n",
        "\n",
        "data_url = base_url + \"getCollectionValues\"\n",
        "data = requests.get(data_url)\n",
        "\n",
        "if data.text != \"\":\n",
        "    notFound=[]\n",
        "    data = data.json()\n",
        "    for x in data:\n",
        "        collection = x['Collection']\n",
        "        patient_url = base_url + \"getPatientByCollectionAndModality?Collection=\" + collection + \"&Modality=\" + modality\n",
        "        patients = requests.get(patient_url)\n",
        "        if patients.text != \"\":\n",
        "            patients = patients.json()\n",
        "            print(collection, 'has', len(patients), 'patients with', modality, 'modality') \n",
        "        else:\n",
        "            notFound.append(collection)\n",
        "    print('The following collections have no patients with', modality, 'modality:', notFound)\n",
        "else:\n",
        "    print(\"Modality not found.\")"
      ],
      "metadata": {
        "id": "Stkuq_-LXISg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create a dataframe that shows patient counts, modalities, body parts for all collections\n",
        "# note: this can take >6 minutes to run\n",
        "\n",
        "resultsList = []\n",
        "\n",
        "# get list of available collections\n",
        "collection_url = base_url + \"getCollectionValues\"\n",
        "collection_data = requests.get(collection_url).json()\n",
        "\n",
        "# loop through list of collections to populate dataframe\n",
        "for x in collection_data:\n",
        "    collectionName = x['Collection']\n",
        "    patient_url = base_url + \"getPatient?Collection=\" + collectionName\n",
        "    patients = requests.get(patient_url).json()\n",
        "    clean_PatientIds = set(item['PatientId'] for item in patients)\n",
        "    patientCount = len(clean_PatientIds)\n",
        "    modality_url = base_url + \"getModalityValues?Collection=\" + collectionName\n",
        "    modalities = requests.get(modality_url).json()\n",
        "    clean_modalities = set(item['Modality'] for item in modalities)\n",
        "    bodyPart_url = base_url + \"getBodyPartValues?Collection=\" + collectionName\n",
        "    bodyParts = requests.get(bodyPart_url).json()\n",
        "    clean_bodyParts = set()\n",
        "    for item in bodyParts:\n",
        "        if len(item):\n",
        "            clean_bodyParts.add(item['BodyPartExamined'])\n",
        "        else:\n",
        "            clean_bodyParts.add('Not Specified')\n",
        "    data = [collectionName, patientCount, clean_modalities, clean_bodyParts]\n",
        "    resultsList.append(data)\n",
        "    df = pd.DataFrame(columns=['Collection', 'Subjects', 'Modalities', 'BodyParts'], data=resultsList)\n",
        "    \n",
        "display(df)\n",
        "\n",
        "# optional export to CSV\n",
        "# df.to_csv('collection_metadata.csv')"
      ],
      "metadata": {
        "id": "6ZMlju-weMbn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.2 Downloading data with the REST API\n",
        "Here are some examples of how to download data from ***public collections*** using the API.  In examples that would create large downloads there is some code included to limit the download to the first few series.  This can be commented out if you're ready to download full datasets.\n",
        "\n",
        "Remember, if you'd like to see examples for downloading a ***restricted collection*** check out [this notebook](https://github.com/kirbyju/TCIA_Notebooks/blob/main/ACNS0332/ACNS0332.ipynb) which shows examples with the additional steps necessary to create a secure token using your TCIA login credentials."
      ],
      "metadata": {
        "id": "oLIs83GT7tvp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import requests, zipfile\n",
        "from io import BytesIO"
      ],
      "metadata": {
        "id": "NWTUXJQIVKsM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "First let's look at how to download an individual series as a zip file based on a SeriesInstanceUID and print some useful information about it with the \"getSeriesMetaData\" endpoint. In particular, the Data Description URI included in the Series Metadata output takes you to the home page for the dataset where you can find valuable supporting data that are not available via our APIs (e.g. clinical spreadsheets, non-DICOM segmentation data) and find answers to common questions you might have about the dataset."
      ],
      "metadata": {
        "id": "FlesywjTGzBJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# example PET scan\n",
        "seriesInstanceUID=\"1.3.6.1.4.1.14519.5.2.1.7009.2401.163884424533721336163307900458\"\n",
        "data_url = base_url + \"getImage?SeriesInstanceUID=\" + seriesInstanceUID\n",
        "request = requests.get(data_url)\n",
        "file = zipfile.ZipFile(BytesIO(request.content))\n",
        "print(\"File list:\",file.namelist())\n",
        "file.extractall(path = \"apiDownload/\" + seriesInstanceUID)\n",
        "\n",
        "metadata_url = base_url + \"getSeriesMetaData?SeriesInstanceUID=\" + seriesInstanceUID\n",
        "metadata = requests.get(metadata_url).json()\n",
        "print(\"Series Metadata:\",metadata)\n"
      ],
      "metadata": {
        "id": "TaK53_Dz_qlC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's define a generic download function that we can re-use for the remaining use cases.  This will take a list of series UIDs as the input, download each scan, and create a dataframe/CSV that contains the metadata about each of those scans.  It also accepts an optional parameter to specify a file name if you'd like a CSV export of the dataframe."
      ],
      "metadata": {
        "id": "ZVgrfvLA0MZj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# define a function to accept a list of seriesInstanceUIDs and download it\n",
        "# reminder: this only downloads the first 3 scans unless you comment out that section\n",
        "\n",
        "def downloadSeries(series_data, csv_filename=\"\"):  \n",
        "    manifestDF=pd.DataFrame()\n",
        "    seriesUID = ''\n",
        "    count = 0\n",
        "    for x in series_data:\n",
        "        seriesUID = x['SeriesInstanceUID']\n",
        "        data_url = base_url + \"getImage?SeriesInstanceUID=\" + seriesUID\n",
        "        print(\"Downloading \" + data_url)\n",
        "        data = requests.get(data_url)\n",
        "        file = zipfile.ZipFile(BytesIO(data.content))\n",
        "        # print(file.namelist())\n",
        "        file.extractall(path = \"apiDownload/\" + collection + \"/\" + seriesUID)\n",
        "        # write the series metadata to a dataframe\n",
        "        metadata_url = base_url + \"getSeriesMetaData?SeriesInstanceUID=\" + seriesUID\n",
        "        metadata = requests.get(metadata_url).json()\n",
        "        newRow = pd.DataFrame.from_dict(metadata)\n",
        "        tmpManifest = pd.concat([manifestDF, newRow], ignore_index = True)\n",
        "        tmpManifest.reset_index()\n",
        "        manifestDF = tmpManifest\n",
        "        # Repeat n times for demo purposes - comment out these next 3 lines to download a full results\n",
        "        count += 1;\n",
        "        if count == 3:\n",
        "            break  \n",
        "    # display manifest dataframe and/or save manifest to CSV file\n",
        "    if csv_filename != \"\":\n",
        "        manifestDF.to_csv(csv_filename + '.csv')\n",
        "        display(manifestDF)\n",
        "    else:\n",
        "        display(manifestDF)"
      ],
      "metadata": {
        "id": "dzwP36uU0LfX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's use the getSeries function we created earlier together with the downloadSeries function to download an entire collection (or just the first 3 scans if you didn't modify the downloadSeries function). "
      ],
      "metadata": {
        "id": "h8x5zGGfqZ-m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# choose collection\n",
        "collection = \"NSCLC-Radiomics\"\n",
        "\n",
        "# call getSeries function to retrieve scan metadata for the whole collection\n",
        "series_data = getSeries(collection)\n",
        "\n",
        "# feed series_data to our downloadSeries function\n",
        "downloadSeries(series_data, collection + \"_full_Collection\")"
      ],
      "metadata": {
        "id": "2XVUkw5vgMZX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can also leverage the flexability to specify Collection + modality for the getSeries function and feed that subset to the downloadSeries function."
      ],
      "metadata": {
        "id": "i7Pw0jvy4HO8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# choose collection\n",
        "collection = \"NSCLC-Radiomics\"\n",
        "modality = \"SEG\"\n",
        "\n",
        "# call getSeries function to retrieve scan metadata for the whole collection\n",
        "series_data = getSeries(collection, modality)\n",
        "\n",
        "# feed series_data to our downloadSeries function\n",
        "downloadSeries(series_data, collection + \"_full_Collection\")"
      ],
      "metadata": {
        "id": "d5TAEkFmVtgg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "It's possible to use https://nbia.cancerimagingarchive.net to create a \"[Shared Cart](https://wiki.cancerimagingarchive.net/display/NBIA/TCIA+Radiology+Portal+User+Guide#TCIARadiologyPortalUserGuide-SharingDatainYourCart)\" which includes a specific set of scans you'd like to share with others. After creating a Shared Cart you receive a URL like https://nbia.cancerimagingarchive.net/nbia-search/?saved-cart=nbia-49121659384603347 which can be shared with others.  Try clicking the link to see what this looks like on the TCIA website.  Then use the code below to see how you can use the cart name to download the (first 3) related scans via our API."
      ],
      "metadata": {
        "id": "AJw430rwTkJ0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download a \"Shared Cart\" that has been previously created via the NBIA GUI (https://nbia.cancerimagingarchive.net)\n",
        "\n",
        "cartName=\"nbia-49121659384603347\"\n",
        "\n",
        "cart_URL = base_url + \"getContentsByName?name=\" + cartName\n",
        "series_data = requests.get(cart_URL).json()\n",
        "\n",
        "# feed series_data to our downloadSeries function\n",
        "downloadSeries(series_data, collection + \"_full_Collection\")"
      ],
      "metadata": {
        "id": "Wdv62WPyhEg7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.3 Organizing the data (optional)\n",
        "The previous code saves all series in a directory named with the Series Instance UID.  This may be fine for some use cases, but often it is helpful to organize the data in a more descriptive fashion.  Below we'll take advantage of the open source [dicomsort](https://github.com/pieper/dicomsort) tool to save things in a Patient ID > Study Date > Series UID > Image hierachy with descriptive names."
      ],
      "metadata": {
        "id": "QYROrYkH4Hze"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# download https://github.com/pieper/dicomsort and install dependencies\n",
        "\n",
        "!pip install pydicom\n",
        "!wget https://raw.githubusercontent.com/pieper/dicomsort/master/dicomsort.py"
      ],
      "metadata": {
        "id": "9N5rDSG9o_pL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# use dicomsort to organize the data\n",
        "# note: the -s flag creates a symlink instead of making a second copy the data\n",
        "\n",
        "!python dicomsort.py -s apiDownload organizedDICOM/%PatientID/%StudyDate/%SeriesDescription-%SeriesInstanceUID/%InstanceNumber.dcm"
      ],
      "metadata": {
        "id": "lgQ8k8_qpySu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4 Data Visualization\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "GvxNpK1B3xaJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Server-side 2D visualization of specific scans in a browser is possible by using our OHIF Viewer if you know the Series Instance UID of the scan you'd like to view.  For example: https://nbia.cancerimagingarchive.net/viewer/?series=1.3.6.1.4.1.14519.5.2.1.7311.5101.225402322918877902268269283832.  "
      ],
      "metadata": {
        "id": "MSyVLtseE6zy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "NCI also funds a project called the [Imaging Data Commons](https://portal.imaging.datacommons.cancer.gov/), which can be useful for visualizing and analyzing TCIA's public datasets.  They currently do not host any of our limited-access Collections.  \n",
        "\n",
        "You can use the code below to pull up specific studies/series of interest using a StudyInstanceUID or SeriesInstanceUID.  The significant advantage to using the IDC viewer is that their version of OHIF supports loading entire studies (not just individual series) and also overlaying annotations/segmentations.  After entering a UID of interest, run the cell below and click the link to open up their viewer in your browser."
      ],
      "metadata": {
        "id": "-KRki7M55Q8h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# helper function to view a study or a specific series hosted by IDC\n",
        "def get_idc_viewer_url(studyUID, seriesUID=None):\n",
        "  url = \"https://viewer.imaging.datacommons.cancer.gov/viewer/\"+studyUID\n",
        "  if seriesUID is not None:\n",
        "    url = url+\"?seriesInstanceUID=\"+seriesUID\n",
        "  return url\n",
        "\n",
        "print(get_idc_viewer_url(\"1.3.6.1.4.1.14519.5.2.1.6279.6001.321085339464682432111441689315\"))"
      ],
      "metadata": {
        "id": "EzSJga6F5yif"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Acknowledgements\n",
        "TCIA is funded by the [Cancer Imaging Program (CIP)](https://imaging.cancer.gov/), a part of the United States [National Cancer Institute (NCI)](https://www.cancer.gov/), and is managed by the [Frederick National Laboratory for Cancer Research (FNLCR)](https://frederick.cancer.gov/).\n",
        "\n",
        "This notebook was created by [Justin Kirby](https://www.linkedin.com/in/justinkirby82/) and Qinyan Pan.  If you leverage this notebook or any TCIA datasets in your work please be sure to comply with the [TCIA Data Usage Policy](https://wiki.cancerimagingarchive.net/x/c4hF). In particular, make sure to cite the DOI(s) for the specific TCIA datasets you used in addition to the following paper!\n",
        "\n",
        "## TCIA Citation\n",
        "\n",
        "Clark, K., Vendt, B., Smith, K., Freymann, J., Kirby, J., Koppel, P., Moore, S., Phillips, S., Maffitt, D., Pringle, M., Tarbox, L., & Prior, F. (2013). The Cancer Imaging Archive (TCIA): Maintaining and Operating a Public Information Repository. Journal of Digital Imaging, 26(6), 1045–1057. https://doi.org/10.1007/s10278-013-9622-7"
      ],
      "metadata": {
        "id": "DYXsNGcY93B8"
      }
    }
  ]
}